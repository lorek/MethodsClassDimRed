{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorek/MethodsClassDimRed/blob/main/MoCaDR_List_nr_9_Hidden_Markov_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Methods of classification and dimensionality reduction**\n",
        "\n",
        "\n",
        "Paweł Lorek  \n",
        "University of Wrocław\n",
        "\n",
        "# LIST NR 9:  Hidden Markov Models for \"Parts of speach tagging\"\n",
        "\n",
        "\n",
        " <font face=\"Rage\" size=2  > Updated: 19.05.2025 <font>\n",
        "\n"
      ],
      "metadata": {
        "id": "xnNFmcVoGC5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_dq4Vn22t7V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paweł Lorek\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import treebank\n",
        "from nltk.corpus import brown\n",
        "from nltk.tag import hmm\n",
        "import time\n",
        "\n"
      ],
      "metadata": {
        "id": "39RfP2oyGF73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parts of speach tagging:\n",
        "\n",
        "\\begin{array}{ccccc}\n",
        "\\textrm{The} & \\textrm{dog} & \\textrm{ate} & \\textrm{the} & \\textrm{cat} \\\\\n",
        "\\downarrow & \\downarrow & \\downarrow & \\downarrow & \\downarrow\\\\\n",
        "\\textrm{DT} & \\textrm{NN} & \\textrm{VBD} & \\textrm{DT} & \\textrm{NN}\n",
        "\\end{array}"
      ],
      "metadata": {
        "id": "yPQCTC3cjsVs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hD7dxEhdjexs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So-called **Penn's tags** (See https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html or https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n",
        "\n",
        "\\begin{array}{ll|ll}\n",
        "1. & \\textrm{CC}   & \\textrm{Coordinating conjunction}   & 19. & \\textrm{PRP\\$} & \\textrm{Possessive pronoun} \\\\\n",
        "2. & \\textrm{CD}   & \\textrm{Cardinal number}            & 20. & \\textrm{RB}    & \\textrm{Adverb} \\\\\n",
        "3. & \\textrm{DT}   & \\textrm{Determiner}                 & 21. & \\textrm{RBR}   & \\textrm{Adverb, comparative} \\\\\n",
        "4. & \\textrm{EX}   & \\textrm{Existential }  there         & 22. & \\textrm{RBS}   & \\textrm{Adverb, superlative} \\\\\n",
        "5. & \\textrm{FW}   & \\textrm{Foreign word}               & 23. & \\textrm{RP}    & \\textrm{Particle} \\\\\n",
        "6. & \\textrm{IN}   & \\textrm{Preposition or subordinating conjunction} & 24. & \\textrm{SYM}   & \\textrm{Symbol} \\\\\n",
        "7. & \\textrm{JJ}   & \\textrm{Adjective}                  & 25. & \\textrm{TO}    & {to} \\\\\n",
        "8. & \\textrm{JJR}  & \\textrm{Adjective, comparative}     & 26. & \\textrm{UH}    & \\textrm{Interjection} \\\\\n",
        "9. & \\textrm{JJS}  & \\textrm{Adjective, superlative}     & 27. & \\textrm{VB}    & \\textrm{Verb, base form} \\\\\n",
        "10. & \\textrm{LS}  & \\textrm{List item marker}           & 28. & \\textrm{VBD}   & \\textrm{Verb, past tense} \\\\\n",
        "11. & \\textrm{MD}  & \\textrm{Modal}                      & 29. & \\textrm{VBG}   & \\textrm{Verb, gerund or present participle} \\\\\n",
        "12. & \\textrm{NN}  & \\textrm{Noun, singular or mass}     & 30. & \\textrm{VBN}   & \\textrm{Verb, past participle} \\\\\n",
        "13. & \\textrm{NNS} & \\textrm{Noun, plural}               & 31. & \\textrm{VBP}   & \\textrm{Verb, non-3rd person singular present} \\\\\n",
        "14. & \\textrm{NNP} & \\textrm{Proper noun, singular}      & 32. & \\textrm{VBZ}   & \\textrm{Verb, 3rd person singular present} \\\\\n",
        "15. & \\textrm{NNPS}& \\textrm{Proper noun, plural}        & 33. & \\textrm{WDT}   & \\textrm{Wh-determiner} \\\\\n",
        "16. & \\textrm{PDT} & \\textrm{Predeterminer}              & 34. & \\textrm{WP}    & \\textrm{Wh-pronoun} \\\\\n",
        "17. & \\textrm{POS} & \\textrm{Possessive ending}          & 35. & \\textrm{WP\\$}  & \\textrm{Possessive wh-pronoun} \\\\\n",
        "18. & \\textrm{PRP} & \\textrm{Personal pronoun}           & 36. & \\textrm{WRB}   & \\textrm{Wh-adverb} \\\\\n",
        "\\end{array}\n"
      ],
      "metadata": {
        "id": "ktQnPs4Fk9-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data, split into training and test sets"
      ],
      "metadata": {
        "id": "380sA1olqT4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'Brown' corpus\n",
        "nltk.download('brown')\n",
        "\n",
        "#'Tree bank' corpus\n",
        "nltk.download('treebank')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzii8cyaqQT6",
        "outputId": "d0ca2dad-ee14-42ef-c5c2-f69f476f4363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take only 40k\n",
        "\n",
        "all_data = list(brown.tagged_sents()[:40000])\n",
        "print(\"len(all_data) = \", len(all_data))\n",
        "#all_data = list(treebank.tagged_sents()[:5000])\n",
        "\n",
        "train_size = int(0.9*len(all_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXEhVI7KqQWi",
        "outputId": "e4d56e16-44a0-483a-a1e3-f270e8c2a2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(all_data) =  40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data[:2] # two sentences and corresponding speach tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEhDMV4fqQY6",
        "outputId": "0286b01b-e47a-4fe9-ec1c-e96b36eefb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('The', 'AT'),\n",
              "  ('Fulton', 'NP-TL'),\n",
              "  ('County', 'NN-TL'),\n",
              "  ('Grand', 'JJ-TL'),\n",
              "  ('Jury', 'NN-TL'),\n",
              "  ('said', 'VBD'),\n",
              "  ('Friday', 'NR'),\n",
              "  ('an', 'AT'),\n",
              "  ('investigation', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  (\"Atlanta's\", 'NP$'),\n",
              "  ('recent', 'JJ'),\n",
              "  ('primary', 'NN'),\n",
              "  ('election', 'NN'),\n",
              "  ('produced', 'VBD'),\n",
              "  ('``', '``'),\n",
              "  ('no', 'AT'),\n",
              "  ('evidence', 'NN'),\n",
              "  (\"''\", \"''\"),\n",
              "  ('that', 'CS'),\n",
              "  ('any', 'DTI'),\n",
              "  ('irregularities', 'NNS'),\n",
              "  ('took', 'VBD'),\n",
              "  ('place', 'NN'),\n",
              "  ('.', '.')],\n",
              " [('The', 'AT'),\n",
              "  ('jury', 'NN'),\n",
              "  ('further', 'RBR'),\n",
              "  ('said', 'VBD'),\n",
              "  ('in', 'IN'),\n",
              "  ('term-end', 'NN'),\n",
              "  ('presentments', 'NNS'),\n",
              "  ('that', 'CS'),\n",
              "  ('the', 'AT'),\n",
              "  ('City', 'NN-TL'),\n",
              "  ('Executive', 'JJ-TL'),\n",
              "  ('Committee', 'NN-TL'),\n",
              "  (',', ','),\n",
              "  ('which', 'WDT'),\n",
              "  ('had', 'HVD'),\n",
              "  ('over-all', 'JJ'),\n",
              "  ('charge', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'AT'),\n",
              "  ('election', 'NN'),\n",
              "  (',', ','),\n",
              "  ('``', '``'),\n",
              "  ('deserves', 'VBZ'),\n",
              "  ('the', 'AT'),\n",
              "  ('praise', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('thanks', 'NNS'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'AT'),\n",
              "  ('City', 'NN-TL'),\n",
              "  ('of', 'IN-TL'),\n",
              "  ('Atlanta', 'NP-TL'),\n",
              "  (\"''\", \"''\"),\n",
              "  ('for', 'IN'),\n",
              "  ('the', 'AT'),\n",
              "  ('manner', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('which', 'WDT'),\n",
              "  ('the', 'AT'),\n",
              "  ('election', 'NN'),\n",
              "  ('was', 'BEDZ'),\n",
              "  ('conducted', 'VBN'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Porter Stemmer\n",
        "**The Porter Stemming algorithm** (or **Porter Stemmer**) is used to remove the suffixes from an English word and obtain its stem which becomes very useful in the field of Information Retrieval (IR)."
      ],
      "metadata": {
        "id": "pLkzNXXOrsKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\", \"likes\", \"liked\",\"likely\",\"liking\"]\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "for w in words:\n",
        "    print(w, \" : \", porter.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7m9GEair6pX",
        "outputId": "00965325-2464-48f4-d7c7-f4a95fed009d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program  :  program\n",
            "programs  :  program\n",
            "programmer  :  programm\n",
            "programming  :  program\n",
            "programmers  :  programm\n",
            "likes  :  like\n",
            "liked  :  like\n",
            "likely  :  like\n",
            "liking  :  like\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling data and stemming:"
      ],
      "metadata": {
        "id": "HMzvdIhksLjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(all_data)\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "\n",
        "porter = PorterStemmer()\n",
        "train_data = [ [(porter.stem(word.lower()), tag) for word, tag in sent] for sent in all_data[:train_size]]\n",
        "test_data = [ [(porter.stem(word.lower()), tag) for word, tag in sent] for sent in all_data[train_size:]]\n",
        "print(\"\\t\\t took %s seconds \" % round((time.time() - start_time),5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dVnipDDqQbq",
        "outputId": "2cbb7c3b-2c00-41a8-8b91-b3e4c2afe7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t took 12.89008 seconds \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxSgHcj1qQeS",
        "outputId": "c191c43c-6e7a-4876-f10d-59a575e016b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('now', 'RB'),\n",
              " ('af', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('af', 'NN'),\n",
              " ('must', 'MD'),\n",
              " ('both', 'ABX'),\n",
              " ('be', 'BE'),\n",
              " ('tangent', 'JJ'),\n",
              " ('point', 'NNS'),\n",
              " ('on', 'IN'),\n",
              " ('the', 'AT'),\n",
              " ('t', 'NP'),\n",
              " ('compon', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'AT'),\n",
              " ('f-plane', 'NN'),\n",
              " (';', '.'),\n",
              " (';', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TJN2qcMttRxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UxXztKTss-vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $n$-gram taggers:\n",
        "\"predict\" tag for word $w$ using last $n$ words. E.g., for $n=2$, if we are to tag **ate** in sentence `The dog ate the cat`,  we take into account words `dog ate` and check what was most frequent tag for `ate` in training data where  `dog ate` appeared."
      ],
      "metadata": {
        "id": "pDdyAdrKufwg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QJE5MQctKFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bigram tagger:"
      ],
      "metadata": {
        "id": "Y5oJx-yvwAkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Calculating bigram tagger...\", end=\"\", flush=True)\n",
        "start_time = time.time()\n",
        "bigram_tagger = nltk.BigramTagger(train_data)\n",
        "bigram_tagger_eval =   bigram_tagger.evaluate(test_data)\n",
        "print(\"\\t\\t took %s seconds \" % round((time.time() - start_time),5))\n",
        "print(\"bigram tagger evaluation: \", bigram_tagger_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMhVJg7MtSfj",
        "outputId": "76526c14-f924-4a94-e623-2749207bb65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating bigram tagger..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-18c8c3cc7ae5>:4: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  bigram_tagger_eval =   bigram_tagger.evaluate(test_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t took 7.83287 seconds \n",
            "bigram tagger evaluation:  0.3057467908042362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Q2ev2bxtXZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "trigram tagger:"
      ],
      "metadata": {
        "id": "Ts581_57wCpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Calculating trigram tagger...\", end=\"\", flush=True)\n",
        "start_time = time.time()\n",
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "trigram_tagger_eval =   trigram_tagger.evaluate(test_data)\n",
        "print(\"\\t\\t took %s seconds \" % round((time.time() - start_time),5))\n",
        "print(\"trigram tagger evaluation: \", trigram_tagger_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xq7INrHteJE",
        "outputId": "76140d5a-e436-451b-98f2-877ea685edff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating trigram tagger...\t\t took 5.14783 seconds \n",
            "trigram tagger evaluation:  0.14064307453869565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4ddcf6b6ff33>:4: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  trigram_tagger_eval =   trigram_tagger.evaluate(test_data)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQ18T3gAwFAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Model tagger\n",
        "\n",
        "Hidden states: tags\n",
        "Observations: sentences\n",
        "\n"
      ],
      "metadata": {
        "id": "q7D_pnROwFTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://raw.githubusercontent.com/lorek/MethodsClassDimRed/main/figures/hmm_speach_tag.png)"
      ],
      "metadata": {
        "id": "8f9shNDF6zVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE: may take ~ 5 min**"
      ],
      "metadata": {
        "id": "suVrlxhg7Kd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Calculating Hmm tagger...\", end=\"\", flush=True)\n",
        "start_time = time.time()\n",
        "hmm_trainer = hmm.HiddenMarkovModelTrainer()\n",
        "hmm_tagger = hmm_trainer.train_supervised(train_data)\n",
        "hmm_tagger_eval = hmm_tagger.evaluate(test_data)\n",
        "print(\"\\t\\t took %s seconds \" % round((time.time() - start_time),5))\n",
        "print(\"hmm_tagger: \",hmm_tagger_eval )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_oHppf3tg-8",
        "outputId": "5b386297-537a-454b-cd89-72a4192ab0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Hmm tagger..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-44a150552f15>:5: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  hmm_tagger_eval = hmm_tagger.evaluate(test_data)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:334: RuntimeWarning: overflow encountered in cast\n",
            "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:336: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:332: RuntimeWarning: overflow encountered in cast\n",
            "  P[i] = self._priors.logprob(si)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/tag/hmm.py:364: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t took 280.38428 seconds \n",
            "hmm_tagger:  0.7256339951328554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Comparison:\")\n",
        "print(\"bigram tagger: \\t\\t\", bigram_tagger_eval)\n",
        "print(\"trigram tagger: \\t\", trigram_tagger_eval)\n",
        "print(\"hmm_tagger: \\t\\t\",hmm_tagger_eval )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOLqJwnqteYL",
        "outputId": "b0bec3ee-41b4-4951-bb12-fc16d71f5816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison:\n",
            "bigram tagger: \t\t 0.30001211280323303\n",
            "trigram tagger: \t 0.13882373668968098\n",
            "hmm_tagger: \t\t 0.7256339951328554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uEdHMXSGv5Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9.1\n",
        "* We performed speech tagging for `brown` dataset. Do the same for `treebank` dataset. Compare results with and without stemming."
      ],
      "metadata": {
        "id": "xLH47EPMHIHG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6AMthRd4HtFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remark:\n",
        "An extension of HMM to continuous observations **and** hidden states: Kalman filter\n",
        "\n",
        "[YouTube: Kalman-Filter, GPS](https://www.youtube.com/watch?v=ZYexI6_zUMk)"
      ],
      "metadata": {
        "id": "cNTdKMmcuA1l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmmbUSlDuDWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}